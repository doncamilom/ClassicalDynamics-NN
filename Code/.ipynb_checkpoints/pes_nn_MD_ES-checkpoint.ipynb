{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculos de energía molecular con redes neuronales.\n",
    "\\\n",
    "<font color='green'>\n",
    "## Aplicación en dinámica molecular.\n",
    "\n",
    "</font>\n",
    "    \n",
    "---\n",
    "\n",
    "## 1. Machine learning\n",
    "\n",
    "    Básicamente: Queremos encontrar una función matemática que reproduzca el comportamiento de un conjunto de datos.\n",
    "\n",
    "##### Ejemplo: Regresión lineal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 80\n",
    "xs = np.random.random(N)*9-4\n",
    "ys = 0.3*xs + 2.1 +  np.random.normal(size=N,scale=0.3)\n",
    "f = np.poly1d(np.polyfit(xs,ys,deg=1))([-4,5])\n",
    "\n",
    "plt.plot(xs,ys,'b.'); plt.plot([-4,5],f,'-r'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos a seguir:\n",
    "\n",
    "    1. Proponemos un modelo:\n",
    "<font size=6>\n",
    "$$\\hat{Y} = mX + b$$ \n",
    "</font>\n",
    "\n",
    "    2. Optimizamos los parámetros: Minimiza la diferencia entre el dato real y el valor que da nuestra función.\n",
    "\n",
    "<img src=\"./Images/Linear_least_squares_example2.png\" width='150'>\n",
    "\n",
    "---\n",
    "\n",
    "## Pero qué pasa si el modelo no es suficiente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 80\n",
    "xs = np.random.random(N)*9-4\n",
    "ys = np.sin(xs) + np.random.normal(size=N,scale=0.15)\n",
    "f = np.poly1d(np.polyfit(xs,ys,deg=1))([-4,5])\n",
    "\n",
    "plt.plot(xs,ys,'b.'); plt.plot([-4,5],f,'-r'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Visión computacional. \n",
    "\\\n",
    "\\\n",
    "<font size=6>\n",
    "    Tarea: Hacer que un computador pueda clasificar imágenes.\n",
    "</font>\n",
    "\n",
    "<img src=\"Images/f_dogvsmuff.png\" width='400'>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<font color='red' size=6>\n",
    "    Tenemos que usar modelos más complejos.\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "# 1. Te consigues los datos:\n",
    "<img src=\"Images/chihuahua_vs_muffin_400px_web.jpg\" width='400'>\n",
    "\n",
    "# 2. Y un modelo suficientemente poderoso\n",
    "\n",
    "- Redes neuronales:\n",
    "<img src=\"Images/neuralnet.png\" width='500'>\n",
    "\n",
    "\n",
    "Cada neurona:\n",
    "\n",
    "<font size=\"6\" color='blue'>\n",
    "$$\n",
    "N_i = \\sigma (w_1^ix_1 + w_2^ix_2 + w_3^ix_3 + ...)\n",
    "$$\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#28e425' size=6>\n",
    "    Pregunta: Colisión de moléculas\n",
    "</font>\n",
    "\n",
    "## Usamos ecuación de Newton para cada átomo:\n",
    "<br>\n",
    "<font color='#a826cf' size=6>\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    F&=ma\\\\\n",
    "    F&=-\\nabla E\n",
    "    \\end{align*}\n",
    "    $$\n",
    "</font>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<font color='black' size=6>\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\Rightarrow  a = -\\frac{1}{m} \\nabla E\n",
    "    \\end{align*}\n",
    "    $$\n",
    "</font>\n",
    "<br>\n",
    "<br>\n",
    "<font color='black' size=6>\n",
    "    Con estas ecuaciones, podemos usar algoritmos para calcular una trayectoria.\n",
    "</font>\n",
    "\n",
    "<img src=\"Images/PES_img_path.png\" width='500'>\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"Images/arjona.jpeg\" width='400'>\n",
    "<font size=1>\n",
    "https://www.generadormemes.com/imagenes/ricardo-arjona-el-problema/\n",
    "</font>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<font color='black' size=6>\n",
    "    Tenemos que calcular el gradiente de la energía en cada punto!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<font color='#4fa072' size=6>\n",
    "      La energía es una función de las coordenadas!\n",
    "</font>\n",
    "\n",
    "# Podemos usar redes neuronales para aproximar una PES.\n",
    "De esta manera es más barato computacionalmente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas:\n",
    "\n",
    "- [ ] Construir conjunto de datos.\n",
    "- [ ] Construir red neuronal (Elegir arquitectura)\n",
    "- [ ] Entrenar NN.\n",
    "    - [ ] Evaluar qué tan buena es\n",
    "- [ ] Ahora sí, corramos trayectorias!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Construir conjunto de datos.\n",
    "\n",
    "### El sistema que vamos a usar es H$_2$CO$^+$.\n",
    "\n",
    "<font size=3.5>\n",
    "    La idea es empezar desde estructuras relevantes (mínimos, TSs), como los reportados en  <a href=\"https://aip.scitation.org/doi/10.1063/1.2181571\">Moyano 2006</a> \n",
    "</font>\n",
    "\n",
    "\n",
    "<img src=\"Images/h2co_min.png\" width='200'>\n",
    "\n",
    "<img src=\"Images/Structs.png\" width='900'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos a generar algunas estructuras nuevas, alrededor de estas estructuras relevantes.\n",
    "\n",
    "### Por ejemplo, si estas son los mínimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "seeds_x = [0,1,2]\n",
    "seeds_y = [-1,2,0]\n",
    "ax.scatter(seeds_x,seeds_y,s=100,marker='x',linewidths=5,color='b')\n",
    "ax.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos algunas estructuras aleatorias alrededor de cada punto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(15,5),sharey=True)\n",
    "\n",
    "new_pts_x = [] ; new_pts_y = []\n",
    "\n",
    "scal = 0.5\n",
    "NperPt = 10\n",
    "for i in range(3):\n",
    "    new_pts_x = new_pts_x + list(np.random.normal(size=NperPt,loc=seeds_x[i],scale=scal))\n",
    "    new_pts_y = new_pts_y + list(np.random.normal(size=NperPt,loc=seeds_y[i],scale=scal))\n",
    "    ax[i].scatter(seeds_x,seeds_y,s=100,marker='x',linewidths=5,color='b')\n",
    "    ax[i].scatter(new_pts_x,new_pts_y,s=100,marker='x',linewidths=1,color='r')\n",
    "    ax[i].axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora sí, a hacer todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux import *\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las columnas son: coordenadas xyz de O, C, H1, H2 (Ox, Oy, Oz, Cx, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m10</th>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.227835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142721</td>\n",
       "      <td>0.230513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.966525</td>\n",
       "      <td>9.074669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.712857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m11</th>\n",
       "      <td>12.285352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.190886</td>\n",
       "      <td>12.574280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.136145</td>\n",
       "      <td>-0.039439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055729</td>\n",
       "      <td>0.152842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.093536</td>\n",
       "      <td>0.201882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.174882</td>\n",
       "      <td>0.927414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.034873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.733547</td>\n",
       "      <td>0.869755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.691461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m2</th>\n",
       "      <td>-0.022028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335390</td>\n",
       "      <td>0.063013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115731</td>\n",
       "      <td>1.009366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.441728</td>\n",
       "      <td>-0.937213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.710607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1         2          3    4         5         6    7   \\\n",
       "m10   0.018902  0.0  0.007275  -0.227835  0.0  1.142721  0.230513  0.0   \n",
       "m11  12.285352  0.0 -4.190886  12.574280  0.0 -3.136145 -0.039439  0.0   \n",
       "m12   0.000000  0.0  0.000000   0.000000  0.0  1.093536  0.201882  0.0   \n",
       "m1    0.000000  0.0  1.217334   0.000000  0.0  0.000000  0.819430  0.0   \n",
       "m2   -0.022028  0.0  1.335390   0.063013  0.0  0.115731  1.009366  0.0   \n",
       "\n",
       "           8         9    10         11  \n",
       "m10 -0.966525  9.074669  0.0 -17.712857  \n",
       "m11 -0.055729  0.152842  0.0   0.657169  \n",
       "m12 -3.174882  0.927414  0.0  -3.034873  \n",
       "m1  -0.733547  0.869755  0.0   1.691461  \n",
       "m2  -0.441728 -0.937213  0.0   1.710607  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = loadCoords(file='../Data/Structs.xyz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute energy for these initial configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ya tenemos las 'Semillas'. Vamos a generar datos alrededor de estas (que sean ~1500 configuraciones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>-0.123725</td>\n",
       "      <td>-0.061801</td>\n",
       "      <td>-0.011710</td>\n",
       "      <td>-0.112710</td>\n",
       "      <td>-0.070765</td>\n",
       "      <td>1.109733</td>\n",
       "      <td>3.054768</td>\n",
       "      <td>-0.079845</td>\n",
       "      <td>2.102449</td>\n",
       "      <td>-0.159884</td>\n",
       "      <td>0.058224</td>\n",
       "      <td>-0.998602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0.038931</td>\n",
       "      <td>-0.021160</td>\n",
       "      <td>-0.148109</td>\n",
       "      <td>-0.053505</td>\n",
       "      <td>-0.012961</td>\n",
       "      <td>1.181142</td>\n",
       "      <td>2.968534</td>\n",
       "      <td>-0.123110</td>\n",
       "      <td>2.102328</td>\n",
       "      <td>0.054858</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>-1.056868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>-0.154436</td>\n",
       "      <td>-0.179457</td>\n",
       "      <td>0.030558</td>\n",
       "      <td>1.145014</td>\n",
       "      <td>3.008393</td>\n",
       "      <td>-0.154101</td>\n",
       "      <td>1.903491</td>\n",
       "      <td>0.074432</td>\n",
       "      <td>-0.015080</td>\n",
       "      <td>-1.090272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>-0.054954</td>\n",
       "      <td>-0.140678</td>\n",
       "      <td>-0.251776</td>\n",
       "      <td>-0.031747</td>\n",
       "      <td>-0.029871</td>\n",
       "      <td>1.288591</td>\n",
       "      <td>2.890288</td>\n",
       "      <td>0.141423</td>\n",
       "      <td>2.136830</td>\n",
       "      <td>0.122562</td>\n",
       "      <td>0.074606</td>\n",
       "      <td>-0.905727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0.030255</td>\n",
       "      <td>-0.049558</td>\n",
       "      <td>0.097189</td>\n",
       "      <td>-0.116205</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>1.111518</td>\n",
       "      <td>2.909554</td>\n",
       "      <td>-0.063856</td>\n",
       "      <td>1.976406</td>\n",
       "      <td>-0.159433</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>-0.891523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "1520 -0.123725 -0.061801 -0.011710 -0.112710 -0.070765  1.109733  3.054768   \n",
       "1521  0.038931 -0.021160 -0.148109 -0.053505 -0.012961  1.181142  2.968534   \n",
       "1522  0.015733  0.041281 -0.154436 -0.179457  0.030558  1.145014  3.008393   \n",
       "1523 -0.054954 -0.140678 -0.251776 -0.031747 -0.029871  1.288591  2.890288   \n",
       "1524  0.030255 -0.049558  0.097189 -0.116205  0.004355  1.111518  2.909554   \n",
       "\n",
       "            7         8         9         10        11  \n",
       "1520 -0.079845  2.102449 -0.159884  0.058224 -0.998602  \n",
       "1521 -0.123110  2.102328  0.054858  0.039862 -1.056868  \n",
       "1522 -0.154101  1.903491  0.074432 -0.015080 -1.090272  \n",
       "1523  0.141423  2.136830  0.122562  0.074606 -0.905727  \n",
       "1524 -0.063856  1.976406 -0.159433  0.029585 -0.891523  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loop through the initial configurations and create new examples\n",
    "Nsamples = 1500\n",
    "\n",
    "NperStruct = int(Nsamples/df.shape[0])\n",
    "for struct in df.index:\n",
    "    OrigCoords = df.loc[struct]\n",
    "    for j in range(NperStruct):\n",
    "        newExamp = OrigCoords + np.random.normal(loc=0,scale=0.1,size=12)\n",
    "        df = df.append(newExamp)\n",
    "        \n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## También tenemos que calcular la energía en cada una de estas nuevas configuraciones.\n",
    "<br>\n",
    "<font size=6 color='red'>\n",
    "    sino, pues el algoritmo no tiene de donde aprender\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 52s, sys: 48.7 s, total: 23min 41s\n",
      "Wall time: 25min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.227835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142721</td>\n",
       "      <td>0.230513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.966525</td>\n",
       "      <td>9.074669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.712857</td>\n",
       "      <td>-113.424919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.285352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.190886</td>\n",
       "      <td>12.574280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.136145</td>\n",
       "      <td>-0.039439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055729</td>\n",
       "      <td>0.152842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657169</td>\n",
       "      <td>-113.401075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.093536</td>\n",
       "      <td>0.201882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.174882</td>\n",
       "      <td>0.927414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.034873</td>\n",
       "      <td>-113.401458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.733547</td>\n",
       "      <td>0.869755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.691461</td>\n",
       "      <td>-113.514051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335390</td>\n",
       "      <td>0.063013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115731</td>\n",
       "      <td>1.009366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.441728</td>\n",
       "      <td>-0.937213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.710607</td>\n",
       "      <td>-113.519105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1         2          3    4         5         6    7  \\\n",
       "0   0.018902  0.0  0.007275  -0.227835  0.0  1.142721  0.230513  0.0   \n",
       "1  12.285352  0.0 -4.190886  12.574280  0.0 -3.136145 -0.039439  0.0   \n",
       "2   0.000000  0.0  0.000000   0.000000  0.0  1.093536  0.201882  0.0   \n",
       "3   0.000000  0.0  1.217334   0.000000  0.0  0.000000  0.819430  0.0   \n",
       "4  -0.022028  0.0  1.335390   0.063013  0.0  0.115731  1.009366  0.0   \n",
       "\n",
       "          8         9   10         11      energy  \n",
       "0 -0.966525  9.074669  0.0 -17.712857 -113.424919  \n",
       "1 -0.055729  0.152842  0.0   0.657169 -113.401075  \n",
       "2 -3.174882  0.927414  0.0  -3.034873 -113.401458  \n",
       "3 -0.733547  0.869755  0.0   1.691461 -113.514051  \n",
       "4 -0.441728 -0.937213  0.0   1.710607 -113.519105  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Finally, calculate the energies for these configurations\n",
    "df['energy'] = df.apply(HFenergy,axis=1)\n",
    "\n",
    "#Select all configurations that didn't return an error\n",
    "df = df[df.energy != 0.0]\n",
    "df.to_csv('../Data/newEDF.csv',index=False)  #Save\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>-0.059597</td>\n",
       "      <td>0.045899</td>\n",
       "      <td>0.023483</td>\n",
       "      <td>0.201739</td>\n",
       "      <td>0.098260</td>\n",
       "      <td>1.040121</td>\n",
       "      <td>3.149622</td>\n",
       "      <td>-0.023382</td>\n",
       "      <td>2.197340</td>\n",
       "      <td>-0.022247</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>-1.125355</td>\n",
       "      <td>-113.387267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>0.082468</td>\n",
       "      <td>-0.058548</td>\n",
       "      <td>-0.152272</td>\n",
       "      <td>-0.054224</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>1.110995</td>\n",
       "      <td>2.968702</td>\n",
       "      <td>-0.045684</td>\n",
       "      <td>2.097381</td>\n",
       "      <td>0.204792</td>\n",
       "      <td>-0.019811</td>\n",
       "      <td>-1.065161</td>\n",
       "      <td>-113.394427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>-0.142561</td>\n",
       "      <td>-0.139416</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>-0.094565</td>\n",
       "      <td>-0.017217</td>\n",
       "      <td>1.195770</td>\n",
       "      <td>3.109141</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>2.139305</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.086349</td>\n",
       "      <td>-0.981902</td>\n",
       "      <td>-113.419421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>-0.071759</td>\n",
       "      <td>0.038233</td>\n",
       "      <td>-0.124448</td>\n",
       "      <td>0.077995</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>1.152396</td>\n",
       "      <td>2.948923</td>\n",
       "      <td>0.028941</td>\n",
       "      <td>2.061696</td>\n",
       "      <td>0.073194</td>\n",
       "      <td>-0.114710</td>\n",
       "      <td>-0.950063</td>\n",
       "      <td>-113.374957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>-0.031120</td>\n",
       "      <td>0.085282</td>\n",
       "      <td>-0.034407</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>3.006498</td>\n",
       "      <td>0.069126</td>\n",
       "      <td>2.009551</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>-0.214376</td>\n",
       "      <td>-0.823244</td>\n",
       "      <td>-113.403712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1470 -0.059597  0.045899  0.023483  0.201739  0.098260  1.040121  3.149622   \n",
       "1471  0.082468 -0.058548 -0.152272 -0.054224  0.015134  1.110995  2.968702   \n",
       "1472 -0.142561 -0.139416  0.004717 -0.094565 -0.017217  1.195770  3.109141   \n",
       "1473 -0.071759  0.038233 -0.124448  0.077995  0.060714  1.152396  2.948923   \n",
       "1474 -0.031120  0.085282 -0.034407  0.067199  0.058419  1.132609  3.006498   \n",
       "\n",
       "             7         8         9        10        11      energy  \n",
       "1470 -0.023382  2.197340 -0.022247  0.013988 -1.125355 -113.387267  \n",
       "1471 -0.045684  2.097381  0.204792 -0.019811 -1.065161 -113.394427  \n",
       "1472 -0.067436  2.139305  0.008012  0.086349 -0.981902 -113.419421  \n",
       "1473  0.028941  2.061696  0.073194 -0.114710 -0.950063 -113.374957  \n",
       "1474  0.069126  2.009551  0.060714 -0.214376 -0.823244 -113.403712  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../Data/newEDF.csv')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#dd2323' size=7>\n",
    "    Entre más datos tengamos, mejor.\n",
    "</font>\n",
    "\n",
    "### Podemos hacer un truco: aprovechar que hay 2 átomos iguales, así que si intercambiamos 1 átomo de H por el otro, la energía es la misma!\n",
    "<br>\n",
    "<font color='#e4238a' size=6>\n",
    "Esto nos aumenta la cantidad de datos x2, ¡sin tener que calcular nada más!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Permutational symmetry considerations: energy is the same upon H exchange\n",
    "#O,C,H1,H2 --> O,C,H2,H1\n",
    "newdf = dataset.copy()\n",
    "h1 = newdf.loc[:,['6','7','8']].copy()\n",
    "h2 = newdf.loc[:,['9','10','11']].copy()\n",
    "\n",
    "newdf.loc[:,['6','7','8']] = h2.values\n",
    "newdf.loc[:,['9','10','11']] = h1.values\n",
    "\n",
    "newdf = newdf.reset_index(drop=True)\n",
    "\n",
    "dataset = pd.concat([dataset,newdf])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalmente, vamos a reducir los grados de libertad:\n",
    "\n",
    "## Para la energía, solo nos interesan posiciones relativas (como en la matriz Z).\n",
    "<br>\n",
    "<font color='#9f23dd' size=6>\n",
    " En este caso, vamos a calcular todas las distancias atómicas (6 en este caso).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andres/anaconda3/envs/psi4/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "featDF = dataset.drop(columns=['energy']).apply(getInput,axis=1)\n",
    "featDF['energy'] = dataset.energy\n",
    "\n",
    "columns = []\n",
    "#Same loops\n",
    "for i in range(len(atoms)):\n",
    "    for j in range(i+1,len(atoms)):  #Only atoms after ith (not counting it)\n",
    "        columns.append(atoms[i]+atoms[j])\n",
    "featDF.columns = columns + ['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featDF.to_csv(\"../Data/train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'm not using train/test split since we're testing using classical dynamics. The error can be measured with a validation set but this inside the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OC</th>\n",
       "      <th>OH1</th>\n",
       "      <th>OH2</th>\n",
       "      <th>CH1</th>\n",
       "      <th>CH2</th>\n",
       "      <th>H1H2</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>0.951479</td>\n",
       "      <td>0.869650</td>\n",
       "      <td>0.257945</td>\n",
       "      <td>0.458998</td>\n",
       "      <td>0.315535</td>\n",
       "      <td>0.217687</td>\n",
       "      <td>0.146695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>0.785685</td>\n",
       "      <td>1.084761</td>\n",
       "      <td>0.273266</td>\n",
       "      <td>0.456247</td>\n",
       "      <td>0.314429</td>\n",
       "      <td>0.238085</td>\n",
       "      <td>0.139534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>0.834539</td>\n",
       "      <td>0.977270</td>\n",
       "      <td>0.257043</td>\n",
       "      <td>0.458181</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.227140</td>\n",
       "      <td>0.114540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>0.777731</td>\n",
       "      <td>1.173596</td>\n",
       "      <td>0.268184</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.332043</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.159004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>0.853636</td>\n",
       "      <td>1.178109</td>\n",
       "      <td>0.273127</td>\n",
       "      <td>0.506381</td>\n",
       "      <td>0.326015</td>\n",
       "      <td>0.244100</td>\n",
       "      <td>0.130250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OC       OH1       OH2       CH1       CH2      H1H2    energy\n",
       "2945  0.951479  0.869650  0.257945  0.458998  0.315535  0.217687  0.146695\n",
       "2946  0.785685  1.084761  0.273266  0.456247  0.314429  0.238085  0.139534\n",
       "2947  0.834539  0.977270  0.257043  0.458181  0.299389  0.227140  0.114540\n",
       "2948  0.777731  1.173596  0.268184  0.473985  0.332043  0.240000  0.159004\n",
       "2949  0.853636  1.178109  0.273127  0.506381  0.326015  0.244100  0.130250"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "\n",
    "minE = train.energy.min()\n",
    "train.energy = (train.energy - minE)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por fin terminamos de crear el conjunto de datos.\n",
    "\n",
    "\n",
    "# 2. Construir y entrenar la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = keras.Sequential(\n",
    "        [keras.Input(shape=(6,)),\n",
    "         Dense(254,activation='relu'),\n",
    "         Dense(128,activation='relu'),\n",
    "         Dense(128,activation='relu'),\n",
    "         Dense(64,activation='relu'),\n",
    "         Dense(1,activation='linear')]\n",
    "    )\n",
    "    model.compile(optimizer='adam',loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2507 samples, validate on 443 samples\n",
      "Epoch 1/500\n",
      "2507/2507 [==============================] - 1s 201us/sample - loss: 0.0545 - val_loss: 0.0472\n",
      "Epoch 2/500\n",
      "2507/2507 [==============================] - 0s 77us/sample - loss: 0.0496 - val_loss: 0.0474\n",
      "Epoch 3/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0449 - val_loss: 0.0460\n",
      "Epoch 4/500\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0402 - val_loss: 0.0480\n",
      "Epoch 5/500\n",
      "2507/2507 [==============================] - 0s 102us/sample - loss: 0.0396 - val_loss: 0.0402\n",
      "Epoch 6/500\n",
      "2507/2507 [==============================] - 0s 88us/sample - loss: 0.0363 - val_loss: 0.0424\n",
      "Epoch 7/500\n",
      "2507/2507 [==============================] - 0s 82us/sample - loss: 0.0329 - val_loss: 0.0397\n",
      "Epoch 8/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0323 - val_loss: 0.0386\n",
      "Epoch 9/500\n",
      "2507/2507 [==============================] - 0s 98us/sample - loss: 0.0286 - val_loss: 0.0366\n",
      "Epoch 10/500\n",
      "2507/2507 [==============================] - 0s 73us/sample - loss: 0.0285 - val_loss: 0.0346\n",
      "Epoch 11/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0287 - val_loss: 0.0382\n",
      "Epoch 12/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0257 - val_loss: 0.0348\n",
      "Epoch 13/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0268 - val_loss: 0.0397\n",
      "Epoch 14/500\n",
      "2507/2507 [==============================] - 0s 85us/sample - loss: 0.0221 - val_loss: 0.0310\n",
      "Epoch 15/500\n",
      "2507/2507 [==============================] - 0s 133us/sample - loss: 0.0213 - val_loss: 0.0304\n",
      "Epoch 16/500\n",
      "2507/2507 [==============================] - 0s 147us/sample - loss: 0.0204 - val_loss: 0.0319\n",
      "Epoch 17/500\n",
      "2507/2507 [==============================] - 0s 158us/sample - loss: 0.0196 - val_loss: 0.0290\n",
      "Epoch 18/500\n",
      "2507/2507 [==============================] - 0s 159us/sample - loss: 0.0186 - val_loss: 0.0281\n",
      "Epoch 19/500\n",
      "2507/2507 [==============================] - 0s 109us/sample - loss: 0.0218 - val_loss: 0.0270\n",
      "Epoch 20/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0184 - val_loss: 0.0348\n",
      "Epoch 21/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0156 - val_loss: 0.0312\n",
      "Epoch 22/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0160 - val_loss: 0.0335\n",
      "Epoch 23/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0155 - val_loss: 0.0240\n",
      "Epoch 24/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0142 - val_loss: 0.0233\n",
      "Epoch 25/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0151 - val_loss: 0.0254\n",
      "Epoch 26/500\n",
      "2507/2507 [==============================] - 0s 93us/sample - loss: 0.0142 - val_loss: 0.0225\n",
      "Epoch 27/500\n",
      "2507/2507 [==============================] - 0s 84us/sample - loss: 0.0136 - val_loss: 0.0209\n",
      "Epoch 28/500\n",
      "2507/2507 [==============================] - 0s 73us/sample - loss: 0.0119 - val_loss: 0.0232\n",
      "Epoch 29/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0125 - val_loss: 0.0249\n",
      "Epoch 30/500\n",
      "2507/2507 [==============================] - 0s 100us/sample - loss: 0.0111 - val_loss: 0.0255\n",
      "Epoch 31/500\n",
      "2507/2507 [==============================] - 0s 75us/sample - loss: 0.0132 - val_loss: 0.0225\n",
      "Epoch 32/500\n",
      "2507/2507 [==============================] - 0s 84us/sample - loss: 0.0111 - val_loss: 0.0237\n",
      "Epoch 33/500\n",
      "2507/2507 [==============================] - 0s 98us/sample - loss: 0.0114 - val_loss: 0.0240\n",
      "Epoch 34/500\n",
      "2507/2507 [==============================] - 0s 82us/sample - loss: 0.0113 - val_loss: 0.0213\n",
      "Epoch 35/500\n",
      "2507/2507 [==============================] - 0s 74us/sample - loss: 0.0100 - val_loss: 0.0213\n",
      "Epoch 36/500\n",
      "2507/2507 [==============================] - 0s 83us/sample - loss: 0.0095 - val_loss: 0.0209\n",
      "Epoch 37/500\n",
      "2507/2507 [==============================] - 0s 91us/sample - loss: 0.0103 - val_loss: 0.0217\n",
      "Epoch 38/500\n",
      "2507/2507 [==============================] - 0s 85us/sample - loss: 0.0105 - val_loss: 0.0199\n",
      "Epoch 39/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0099 - val_loss: 0.0237\n",
      "Epoch 40/500\n",
      "2507/2507 [==============================] - 0s 77us/sample - loss: 0.0094 - val_loss: 0.0199\n",
      "Epoch 41/500\n",
      "2507/2507 [==============================] - 0s 75us/sample - loss: 0.0097 - val_loss: 0.0258\n",
      "Epoch 42/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0116 - val_loss: 0.0209\n",
      "Epoch 43/500\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.0104 - val_loss: 0.0215\n",
      "Epoch 44/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0106 - val_loss: 0.0282\n",
      "Epoch 45/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0111 - val_loss: 0.0238\n",
      "Epoch 46/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0101 - val_loss: 0.0204\n",
      "Epoch 47/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0099 - val_loss: 0.0216\n",
      "Epoch 48/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0090 - val_loss: 0.0204\n",
      "Epoch 49/500\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0089 - val_loss: 0.0228\n",
      "Epoch 50/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0092 - val_loss: 0.0225\n",
      "Epoch 51/500\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0092 - val_loss: 0.0201\n",
      "Epoch 52/500\n",
      "2507/2507 [==============================] - 0s 74us/sample - loss: 0.0093 - val_loss: 0.0194\n",
      "Epoch 53/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0091 - val_loss: 0.0200\n",
      "Epoch 54/500\n",
      "2507/2507 [==============================] - 0s 76us/sample - loss: 0.0095 - val_loss: 0.0190\n",
      "Epoch 55/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0091 - val_loss: 0.0208\n",
      "Epoch 56/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0085 - val_loss: 0.0202\n",
      "Epoch 57/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0099 - val_loss: 0.0205\n",
      "Epoch 58/500\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.0085 - val_loss: 0.0205\n",
      "Epoch 59/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0096 - val_loss: 0.0222\n",
      "Epoch 60/500\n",
      "2507/2507 [==============================] - 0s 75us/sample - loss: 0.0087 - val_loss: 0.0186\n",
      "Epoch 61/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0078 - val_loss: 0.0214\n",
      "Epoch 62/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0086 - val_loss: 0.0197\n",
      "Epoch 63/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0084 - val_loss: 0.0212\n",
      "Epoch 64/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0090 - val_loss: 0.0188\n",
      "Epoch 65/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0083 - val_loss: 0.0190\n",
      "Epoch 66/500\n",
      "2507/2507 [==============================] - 0s 75us/sample - loss: 0.0090 - val_loss: 0.0197\n",
      "Epoch 67/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0080 - val_loss: 0.0215\n",
      "Epoch 68/500\n",
      "2507/2507 [==============================] - 0s 83us/sample - loss: 0.0075 - val_loss: 0.0199\n",
      "Epoch 69/500\n",
      "2507/2507 [==============================] - 0s 88us/sample - loss: 0.0083 - val_loss: 0.0180\n",
      "Epoch 70/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0076 - val_loss: 0.0185\n",
      "Epoch 71/500\n",
      "2507/2507 [==============================] - 0s 86us/sample - loss: 0.0079 - val_loss: 0.0177\n",
      "Epoch 72/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0076 - val_loss: 0.0182\n",
      "Epoch 73/500\n",
      "2507/2507 [==============================] - 0s 78us/sample - loss: 0.0080 - val_loss: 0.0173\n",
      "Epoch 74/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0080 - val_loss: 0.0179\n",
      "Epoch 75/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0075 - val_loss: 0.0173\n",
      "Epoch 76/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0083 - val_loss: 0.0164\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0081 - val_loss: 0.0202\n",
      "Epoch 78/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0070 - val_loss: 0.0174\n",
      "Epoch 79/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0071 - val_loss: 0.0185\n",
      "Epoch 80/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0077 - val_loss: 0.0191\n",
      "Epoch 81/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0078 - val_loss: 0.0207\n",
      "Epoch 82/500\n",
      "2507/2507 [==============================] - 0s 74us/sample - loss: 0.0082 - val_loss: 0.0213\n",
      "Epoch 83/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0075 - val_loss: 0.0199\n",
      "Epoch 84/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0084 - val_loss: 0.0196\n",
      "Epoch 85/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0083 - val_loss: 0.0175\n",
      "Epoch 86/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0075 - val_loss: 0.0172\n",
      "Epoch 87/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0083 - val_loss: 0.0183\n",
      "Epoch 88/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0079 - val_loss: 0.0220\n",
      "Epoch 89/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0077 - val_loss: 0.0204\n",
      "Epoch 90/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0082 - val_loss: 0.0196\n",
      "Epoch 91/500\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.0068 - val_loss: 0.0178\n",
      "Epoch 92/500\n",
      "2507/2507 [==============================] - 0s 78us/sample - loss: 0.0075 - val_loss: 0.0213\n",
      "Epoch 93/500\n",
      "2507/2507 [==============================] - 0s 74us/sample - loss: 0.0080 - val_loss: 0.0165\n",
      "Epoch 94/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0074 - val_loss: 0.0176\n",
      "Epoch 95/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0070 - val_loss: 0.0190\n",
      "Epoch 96/500\n",
      "2507/2507 [==============================] - 0s 76us/sample - loss: 0.0074 - val_loss: 0.0177\n",
      "Epoch 97/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0053 - val_loss: 0.0167\n",
      "Epoch 98/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0051 - val_loss: 0.0162\n",
      "Epoch 99/500\n",
      "2507/2507 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 100/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0046 - val_loss: 0.0167\n",
      "Epoch 101/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0044 - val_loss: 0.0165\n",
      "Epoch 102/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0045 - val_loss: 0.0168\n",
      "Epoch 103/500\n",
      "2507/2507 [==============================] - 0s 76us/sample - loss: 0.0048 - val_loss: 0.0154\n",
      "Epoch 104/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0046 - val_loss: 0.0177\n",
      "Epoch 105/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0050 - val_loss: 0.0158\n",
      "Epoch 106/500\n",
      "2507/2507 [==============================] - 0s 73us/sample - loss: 0.0043 - val_loss: 0.0136\n",
      "Epoch 107/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0051 - val_loss: 0.0152\n",
      "Epoch 108/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0046 - val_loss: 0.0153\n",
      "Epoch 109/500\n",
      "2507/2507 [==============================] - 0s 81us/sample - loss: 0.0041 - val_loss: 0.0146\n",
      "Epoch 110/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0046 - val_loss: 0.0152\n",
      "Epoch 111/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0048 - val_loss: 0.0156\n",
      "Epoch 112/500\n",
      "2507/2507 [==============================] - 0s 103us/sample - loss: 0.0046 - val_loss: 0.0136\n",
      "Epoch 113/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0046 - val_loss: 0.0142\n",
      "Epoch 114/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0048 - val_loss: 0.0133\n",
      "Epoch 115/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0046 - val_loss: 0.0134\n",
      "Epoch 116/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0044 - val_loss: 0.0149\n",
      "Epoch 117/500\n",
      "2507/2507 [==============================] - 0s 99us/sample - loss: 0.0049 - val_loss: 0.0139\n",
      "Epoch 118/500\n",
      "2507/2507 [==============================] - 0s 109us/sample - loss: 0.0047 - val_loss: 0.0133\n",
      "Epoch 119/500\n",
      "2507/2507 [==============================] - 0s 93us/sample - loss: 0.0042 - val_loss: 0.0146\n",
      "Epoch 120/500\n",
      "2507/2507 [==============================] - 0s 93us/sample - loss: 0.0041 - val_loss: 0.0138\n",
      "Epoch 121/500\n",
      "2507/2507 [==============================] - 0s 81us/sample - loss: 0.0047 - val_loss: 0.0141\n",
      "Epoch 122/500\n",
      "2507/2507 [==============================] - 0s 74us/sample - loss: 0.0045 - val_loss: 0.0130\n",
      "Epoch 123/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0046 - val_loss: 0.0136\n",
      "Epoch 124/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0046 - val_loss: 0.0132\n",
      "Epoch 125/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0047 - val_loss: 0.0146\n",
      "Epoch 126/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0047 - val_loss: 0.0131\n",
      "Epoch 127/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0040 - val_loss: 0.0127\n",
      "Epoch 128/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 129/500\n",
      "2507/2507 [==============================] - 0s 83us/sample - loss: 0.0041 - val_loss: 0.0110\n",
      "Epoch 130/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0042 - val_loss: 0.0135\n",
      "Epoch 131/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0040 - val_loss: 0.0115\n",
      "Epoch 132/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0045 - val_loss: 0.0121\n",
      "Epoch 133/500\n",
      "2507/2507 [==============================] - 0s 67us/sample - loss: 0.0044 - val_loss: 0.0124\n",
      "Epoch 134/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0041 - val_loss: 0.0113\n",
      "Epoch 135/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0047 - val_loss: 0.0143\n",
      "Epoch 136/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0042 - val_loss: 0.0130\n",
      "Epoch 137/500\n",
      "2507/2507 [==============================] - 0s 101us/sample - loss: 0.0049 - val_loss: 0.0122\n",
      "Epoch 138/500\n",
      "2507/2507 [==============================] - 0s 76us/sample - loss: 0.0042 - val_loss: 0.0113\n",
      "Epoch 139/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0044 - val_loss: 0.0117\n",
      "Epoch 140/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0041 - val_loss: 0.0115\n",
      "Epoch 141/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0039 - val_loss: 0.0144\n",
      "Epoch 142/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0043 - val_loss: 0.0115\n",
      "Epoch 143/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0041 - val_loss: 0.0119\n",
      "Epoch 144/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0047 - val_loss: 0.0118\n",
      "Epoch 145/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0042 - val_loss: 0.0121\n",
      "Epoch 146/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0042 - val_loss: 0.0125\n",
      "Epoch 147/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0043 - val_loss: 0.0108\n",
      "Epoch 148/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0041 - val_loss: 0.0105\n",
      "Epoch 149/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0040 - val_loss: 0.0106\n",
      "Epoch 150/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0041 - val_loss: 0.0118\n",
      "Epoch 151/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0043 - val_loss: 0.0122\n",
      "Epoch 152/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0047 - val_loss: 0.0112\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 154/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0042 - val_loss: 0.0109\n",
      "Epoch 155/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0042 - val_loss: 0.0104\n",
      "Epoch 156/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0043 - val_loss: 0.0118\n",
      "Epoch 157/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0041 - val_loss: 0.0121\n",
      "Epoch 158/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0041 - val_loss: 0.0112\n",
      "Epoch 159/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0038 - val_loss: 0.0119\n",
      "Epoch 160/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0045 - val_loss: 0.0118\n",
      "Epoch 161/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0038 - val_loss: 0.0108\n",
      "Epoch 162/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0039 - val_loss: 0.0110\n",
      "Epoch 163/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0040 - val_loss: 0.0116\n",
      "Epoch 164/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0046 - val_loss: 0.0125\n",
      "Epoch 165/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0041 - val_loss: 0.0108\n",
      "Epoch 166/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0039 - val_loss: 0.0111\n",
      "Epoch 167/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0042 - val_loss: 0.0103\n",
      "Epoch 168/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0042 - val_loss: 0.0117\n",
      "Epoch 169/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0037 - val_loss: 0.0121\n",
      "Epoch 170/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0044 - val_loss: 0.0114\n",
      "Epoch 171/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0041 - val_loss: 0.0117\n",
      "Epoch 172/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0047 - val_loss: 0.0106\n",
      "Epoch 173/500\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.0040 - val_loss: 0.0114\n",
      "Epoch 174/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0042 - val_loss: 0.0116\n",
      "Epoch 175/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0041 - val_loss: 0.0107\n",
      "Epoch 176/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0044 - val_loss: 0.0136\n",
      "Epoch 177/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0045 - val_loss: 0.0127\n",
      "Epoch 178/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0038 - val_loss: 0.0125\n",
      "Epoch 179/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0046 - val_loss: 0.0118\n",
      "Epoch 180/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0038 - val_loss: 0.0118\n",
      "Epoch 181/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0041 - val_loss: 0.0105\n",
      "Epoch 182/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0044 - val_loss: 0.0107\n",
      "Epoch 183/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0039 - val_loss: 0.0123\n",
      "Epoch 184/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0042 - val_loss: 0.0108\n",
      "Epoch 185/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0036 - val_loss: 0.0111\n",
      "Epoch 186/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0039 - val_loss: 0.0123\n",
      "Epoch 187/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0039 - val_loss: 0.0128\n",
      "Epoch 188/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0029 - val_loss: 0.0106\n",
      "Epoch 189/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 190/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0029 - val_loss: 0.0106\n",
      "Epoch 191/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0027 - val_loss: 0.0107\n",
      "Epoch 192/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0026 - val_loss: 0.0117\n",
      "Epoch 193/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0031 - val_loss: 0.0118\n",
      "Epoch 194/500\n",
      "2507/2507 [==============================] - 0s 68us/sample - loss: 0.0029 - val_loss: 0.0103\n",
      "Epoch 195/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0027 - val_loss: 0.0103\n",
      "Epoch 196/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0025 - val_loss: 0.0108\n",
      "Epoch 197/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0027 - val_loss: 0.0103\n",
      "Epoch 198/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.0109\n",
      "Epoch 199/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0027 - val_loss: 0.0110\n",
      "Epoch 200/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0026 - val_loss: 0.0112\n",
      "Epoch 201/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0028 - val_loss: 0.0113\n",
      "Epoch 202/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 203/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0026 - val_loss: 0.0110\n",
      "Epoch 204/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0025 - val_loss: 0.0112\n",
      "Epoch 205/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0024 - val_loss: 0.0106\n",
      "Epoch 206/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0027 - val_loss: 0.0112\n",
      "Epoch 207/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0027 - val_loss: 0.0111\n",
      "Epoch 208/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0021 - val_loss: 0.0103\n",
      "Epoch 209/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0021 - val_loss: 0.0104\n",
      "Epoch 210/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0019 - val_loss: 0.0106\n",
      "Epoch 211/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 212/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0020 - val_loss: 0.0103\n",
      "Epoch 213/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0021 - val_loss: 0.0106\n",
      "Epoch 214/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.0107\n",
      "Epoch 215/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0019 - val_loss: 0.0104\n",
      "Epoch 216/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0020 - val_loss: 0.0105\n",
      "Epoch 217/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 218/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 219/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0020 - val_loss: 0.0104\n",
      "Epoch 220/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0019 - val_loss: 0.0102\n",
      "Epoch 221/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 222/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 223/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 224/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 225/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 226/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0019 - val_loss: 0.0105\n",
      "Epoch 227/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0018 - val_loss: 0.0106\n",
      "Epoch 228/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0021 - val_loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 230/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0019 - val_loss: 0.0102\n",
      "Epoch 231/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0020 - val_loss: 0.0105\n",
      "Epoch 232/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0020 - val_loss: 0.0108\n",
      "Epoch 233/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0020 - val_loss: 0.0108\n",
      "Epoch 234/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0020 - val_loss: 0.0102\n",
      "Epoch 235/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.0104\n",
      "Epoch 236/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0019 - val_loss: 0.0106\n",
      "Epoch 237/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0019 - val_loss: 0.0105\n",
      "Epoch 238/500\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0019 - val_loss: 0.0099\n",
      "Epoch 239/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0018 - val_loss: 0.0106\n",
      "Epoch 240/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 241/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.0107\n",
      "Epoch 242/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0018 - val_loss: 0.0104\n",
      "Epoch 243/500\n",
      "2507/2507 [==============================] - 0s 69us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 244/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 245/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0019 - val_loss: 0.0106\n",
      "Epoch 246/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0017 - val_loss: 0.0104\n",
      "Epoch 247/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0017 - val_loss: 0.0107\n",
      "Epoch 248/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 249/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 250/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0018 - val_loss: 0.0107\n",
      "Epoch 251/500\n",
      "2507/2507 [==============================] - 0s 65us/sample - loss: 0.0018 - val_loss: 0.0105\n",
      "Epoch 252/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 253/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0018 - val_loss: 0.0104\n",
      "Epoch 254/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0019 - val_loss: 0.0106\n",
      "Epoch 255/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 256/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0018 - val_loss: 0.0110\n",
      "Epoch 257/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0018 - val_loss: 0.0108\n",
      "Epoch 258/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 259/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0017 - val_loss: 0.0106\n",
      "Epoch 260/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0016 - val_loss: 0.0105\n",
      "Epoch 261/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 262/500\n",
      "2507/2507 [==============================] - 0s 61us/sample - loss: 0.0015 - val_loss: 0.0103\n",
      "Epoch 263/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0015 - val_loss: 0.0103\n",
      "Epoch 264/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0015 - val_loss: 0.0104\n",
      "Epoch 265/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 266/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 267/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0015 - val_loss: 0.0106\n",
      "Epoch 268/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 269/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 270/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 271/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0016 - val_loss: 0.0104\n",
      "Epoch 272/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 273/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0015 - val_loss: 0.0104\n",
      "Epoch 274/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 275/500\n",
      "2507/2507 [==============================] - 0s 62us/sample - loss: 0.0015 - val_loss: 0.0102\n",
      "Epoch 276/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0014 - val_loss: 0.0104\n",
      "Epoch 277/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0015 - val_loss: 0.0101\n",
      "Epoch 278/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0014 - val_loss: 0.0105\n",
      "Epoch 279/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 280/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 281/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 282/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 283/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 284/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 285/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 286/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 287/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 288/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 289/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 290/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 291/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 292/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 293/500\n",
      "2507/2507 [==============================] - 0s 63us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 294/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 295/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 296/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 297/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 298/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0013 - val_loss: 0.0102\n",
      "Epoch 299/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 300/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 301/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 302/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 303/500\n",
      "2507/2507 [==============================] - 0s 70us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 304/500\n",
      "2507/2507 [==============================] - 0s 87us/sample - loss: 0.0012 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 306/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 307/500\n",
      "2507/2507 [==============================] - 0s 72us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 308/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 309/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 310/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 311/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 312/500\n",
      "2507/2507 [==============================] - 0s 64us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 313/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 314/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 315/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 316/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 317/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0012 - val_loss: 0.0104\n",
      "Epoch 318/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 319/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 320/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 321/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 322/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 323/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 324/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 325/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 326/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 327/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 328/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 329/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 330/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 331/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 332/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 333/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0104\n",
      "Epoch 334/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 335/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 336/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 337/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0104\n",
      "Epoch 338/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 339/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 340/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 341/500\n",
      "2507/2507 [==============================] - 0s 79us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 342/500\n",
      "2507/2507 [==============================] - 0s 87us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 343/500\n",
      "2507/2507 [==============================] - 0s 57us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 344/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 345/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 346/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 347/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 348/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 349/500\n",
      "2507/2507 [==============================] - 0s 80us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 350/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 351/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 352/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 353/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 354/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 355/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 356/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 357/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 358/500\n",
      "2507/2507 [==============================] - 0s 90us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 359/500\n",
      "2507/2507 [==============================] - 0s 71us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 360/500\n",
      "2507/2507 [==============================] - 0s 89us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 361/500\n",
      "2507/2507 [==============================] - 0s 93us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 362/500\n",
      "2507/2507 [==============================] - 0s 66us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 363/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 364/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 365/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 366/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 367/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 368/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 369/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 370/500\n",
      "2507/2507 [==============================] - 0s 92us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 371/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 372/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 373/500\n",
      "2507/2507 [==============================] - 0s 58us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 374/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 375/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 376/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 377/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 378/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 379/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 380/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 382/500\n",
      "2507/2507 [==============================] - 0s 56us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 383/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 384/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 385/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 386/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 387/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 388/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 389/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 390/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 391/500\n",
      "2507/2507 [==============================] - 0s 59us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 392/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 393/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 394/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 395/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 396/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 397/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 398/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 399/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 400/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 401/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 402/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 403/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 404/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 405/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 406/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 407/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 408/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 409/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 410/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 411/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 412/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 413/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 414/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 415/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 416/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 417/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 418/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 419/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 420/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 421/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 422/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 423/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 424/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 425/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 426/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 427/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 428/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 429/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 430/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 431/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 432/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 433/500\n",
      "2507/2507 [==============================] - 0s 60us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 434/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 435/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 436/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 437/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 438/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 439/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 440/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 441/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 442/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 443/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 444/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 445/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 446/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 447/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 448/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 449/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 450/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 451/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 452/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 453/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 454/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 455/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 456/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 458/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 459/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 460/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 461/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 462/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 463/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 464/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 465/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 466/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 467/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 468/500\n",
      "2507/2507 [==============================] - 0s 54us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 469/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 470/500\n",
      "2507/2507 [==============================] - 0s 50us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 471/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 472/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 473/500\n",
      "2507/2507 [==============================] - 0s 55us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 474/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 475/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 476/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 477/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 478/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 479/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 480/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 481/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 482/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 483/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 484/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 485/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 486/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 487/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 488/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 489/500\n",
      "2507/2507 [==============================] - 0s 53us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 490/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 491/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 492/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 493/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 494/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 495/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 496/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 497/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 498/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 499/500\n",
      "2507/2507 [==============================] - 0s 51us/sample - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 500/500\n",
      "2507/2507 [==============================] - 0s 52us/sample - loss: 0.0011 - val_loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "\n",
    "xs = train.drop(columns=['energy'])\n",
    "ys = train.energy\n",
    "\n",
    "RedLR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,\n",
    "                                          patience=20,verbose=0)\n",
    "CheckP = keras.callbacks.ModelCheckpoint('../Data/PES.hdf5',monitor=\"val_loss\",save_best_only=True)\n",
    "\n",
    "\n",
    "model.fit(xs,ys,batch_size=32,epochs=500,validation_split=0.15,\n",
    "          callbacks=[RedLR,CheckP]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel()\n",
    "model.load_weights('../Data/PES.hdf5')\n",
    "\n",
    "def E(coords):\n",
    "    return model.predict(coords) + minE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenemos un error promedio de 0.0084 Hartree (5.271 kcal/mol).\n",
    "\n",
    "### Mientras que el trabajo de referencia obtuvo 1.195 kcal/mol. \n",
    "<br>\n",
    "<br>\n",
    "<font color='#109148' size=6>\n",
    "    Peeero: En ese trabajo calcularon Energías, Gradientes y Hessianas para interpolar con expansiones de Taylor.\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Vamos a hacer una prueba rápida: Veamos la calidad de la PES en una IRC de interés.\n",
    "\n",
    "<img src='Images/IRC.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 532 ms, total: 35.7 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "irc = loadCoords_IRC('../Data/ts3.irc')\n",
    "\n",
    "#Some operations before plotting\n",
    "tmp1 = irc.iloc[22:].sort_values(by='energy')\n",
    "tmp2 = irc.iloc[:22]\n",
    "IRC = pd.concat([tmp1,tmp2])\n",
    "\n",
    "#Calculate energies using selected method and basis set (UHF/cc-pVDZ)\n",
    "IRC['HF'] = IRC.drop(columns='energy').apply(HFenergy,axis=1)\n",
    "\n",
    "ircFeats = IRC.drop(columns=['HF','energy']).apply(getInput,axis=1)\n",
    "ircFeats['HF'] = IRC.HF\n",
    "\n",
    "columns = []\n",
    "#Same loops\n",
    "for i in range(len(atoms)):\n",
    "    for j in range(i+1,len(atoms)):  #Only atoms after ith (not counting it)\n",
    "        columns.append(atoms[i]+atoms[j])\n",
    "ircFeats.columns = columns + ['HF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con esto, acabamos de calcular las energías de cada punto en la IRC, con HF/cc-pVDZ. Veamos qué tal es la NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictedIRC = E(ircFeats.drop(columns='HF'))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(predictedIRC,'k.',label='NN')\n",
    "ax.plot(ircFeats.HF.values,label='HF/cc-pVDZ',color='r')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(r'IRC H$_2$CO $\\rightarrow$ HCOH')\n",
    "ax.set_ylabel('E / Hartree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Ahora sí, corramos trayectorias!\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<font color='#1730c7' size=6>\n",
    "    Ya los algoritmos integradores están implementados, sólo falta ponerle condiciones iniciales (posición y velocidad).\n",
    "</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Vamos a simular una colisión entre H y HCO$^+$. Chocamos los dos fragmentos, y vemos qué sale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_conds(v0=10000):\n",
    "    \"\"\"Define coordenadas y velocidades iniciales.\n",
    "    HCO+ muy cerca a mínimo, H entre 7 y 9 Angstrom.\n",
    "    Argumentos: v0 = velocidad relativa entre fragmentos, en m/s\"\"\"\n",
    "    # Definamos posición del fragmento HCO+\n",
    "    xOCH = np.array([[0.000000, 0.000000, -1.598843],\n",
    "                     [0.000000, 0.000000, -0.504771],\n",
    "                     [0.000000, 0.000000, 0.578434]])\n",
    "    # Y posición del H (que sea aleatoria, a entre 6 y 8 Angstrom)\n",
    "    r = np.random.random()*2+6\n",
    "    phi = np.random.random()*np.pi\n",
    "    theta = np.random.random()*2*np.pi\n",
    "    \n",
    "    xH = np.array([[np.sin(phi)*np.cos(theta),\n",
    "                   np.sin(phi)*np.sin(theta),\n",
    "                   np.cos(phi)]])*r\n",
    "    \n",
    "    X0 = np.concatenate([xOCH,xH]).reshape(1,-1)\n",
    "    \n",
    "    # Ahora definimos velocidades (las trayectorias reactivas ocurren por colisiones)\n",
    "    unit = xH - xOCH.mean(axis=0)  # Promedio de distancias\n",
    "    unit = unit/np.linalg.norm(unit)   #Unit vector pointing in the direction HCO to H\n",
    "    V0 = np.zeros(12).reshape(1,-1) \n",
    "    V0[:,9:] = -(v0*unit*1e10).reshape(1,-1)  # Convierte a Ang/s, y le da dirección \n",
    "    return X0,V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9000 m/s is about 41 kJ/mol.\n",
    "\n",
    "# Moyano et al report relative kinetic energies in the range 13.1 to 26.3 kJ/mol, which correspond to 5100 - 7223 m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "Trajectory completed!\n",
      "CPU times: user 1min 44s, sys: 29.7 ms, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "v0 = 20000\n",
    "#Now same traj with our NN PES\n",
    "\n",
    "for i in range(10):\n",
    "    NNtraj = Trajectory(*Init_conds(v0),Nsteps=2000,timeDelta=1e-16,\n",
    "                        saveMolden=f'../Data/NNtraj{i}.txt',\n",
    "                        gradient=Grad,model=model)\n",
    "    NNtraj.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trajectories have been stored to the file `HFtraj.txt` and `NNtraj`. It can be viewed with some visualization program such as [MOLDEN](http://cheminf.cmbi.ru.nl/molden/molden.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/sample-trajNN.gif\" width=\"450\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El código que sigue, corre la misma trayectoria, pero con los gradientes reales (HF/cc-pVDZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HFgrad(model,row):\n",
    "    \"\"\"model is a dummy variable for compatibility\n",
    "    Real gradient at HF/cc-pVDZ.\n",
    "    This is expensive, use only for comparison\n",
    "    Documentation: http://psicode.org/psi4manual/1.3.2/opt.html\n",
    "    \"\"\"\n",
    "    psi4.set_memory('500 MB')\n",
    "\n",
    "    #charge = +1, spin multipicity = 2\n",
    "    h2o = psi4.geometry(\"\"\"\n",
    "    1 2\n",
    "    O {} {} {}\n",
    "    C {} {} {} \n",
    "    H {} {} {}\n",
    "    H {} {} {}\n",
    "    \"\"\".format(*row))\n",
    "    \n",
    "    psi4.set_options({'reference': 'uhf'})\n",
    "    \n",
    "    #Gradient calculated using UHF/cc-pVDZ\n",
    "    try: \n",
    "        #Gradient is returned in Hartree/bohr -> convert to Hartree/ang\n",
    "        return np.array(psi4.gradient('scf/cc-pvdz') ).flatten()  * 1.8897161 \n",
    "    except:  #In case there's a convergence error or alike\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory completed!\n",
      "CPU times: user 31min 47s, sys: 31.3 s, total: 32min 18s\n",
      "Wall time: 34min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X0,V0 = Init_conds(7000)\n",
    "\n",
    "#Let's run a traj with full HF gradients for comparison\n",
    "HFtraj = Trajectory(X0,V0,Nsteps=2000,timeDelta=1e-16,saveMolden='../Data/HFtraj_1.txt',gradient=HFgrad)\n",
    "HFtraj.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory completed!\n"
     ]
    }
   ],
   "source": [
    "NNtraj = Trajectory(X0,V0,Nsteps=2000,timeDelta=1e-16,\n",
    "                        saveMolden=f'../Data/NNtraj_1.txt',\n",
    "                        gradient=Grad,model=model)\n",
    "NNtraj.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psi4",
   "language": "python",
   "name": "psi4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
